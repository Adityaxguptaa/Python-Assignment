{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "### Machine Learning Q&A\n",
        "\n",
        "# 1. What is a parameter?\n",
        "# A parameter is a variable in a machine learning model that is learned from the training data.\n",
        "# It defines the relationship between input and output and is updated during model training.\n",
        "# Examples include weights in a neural network and coefficients in linear regression.\n",
        "\n",
        "# 2. What is correlation?\n",
        "# Correlation is a statistical measure that expresses the strength and direction of the relationship between two variables.\n",
        "# It ranges from -1 to 1, where 1 indicates a perfect positive relationship, -1 indicates a perfect negative relationship, and 0 means no correlation.\n",
        "# Correlation does not imply causation, meaning one variable does not necessarily cause changes in the other.\n",
        "\n",
        "# 3. What does negative correlation mean?\n",
        "# Negative correlation means that as one variable increases, the other decreases.\n",
        "# For example, in financial markets, bond prices and interest rates typically have a negative correlation.\n",
        "# A correlation coefficient close to -1 indicates a strong negative correlation.\n",
        "\n",
        "# 4. Define Machine Learning. What are the main components in Machine Learning?\n",
        "# Machine learning is a field of artificial intelligence that enables computers to learn from data without being explicitly programmed.\n",
        "# The main components of machine learning include data, a model, a loss function, an optimizer, and evaluation metrics.\n",
        "# The model learns patterns from the data, the loss function measures its performance, and the optimizer updates the model parameters to improve predictions.\n",
        "\n",
        "# 5. How does loss value help in determining whether the model is good or not?\n",
        "# The loss value quantifies the difference between the actual and predicted values of the model.\n",
        "# A lower loss value indicates that the model's predictions are close to the true values, implying better performance.\n",
        "# If the loss is high, it means the model is making significant errors, requiring adjustments in parameters or training data.\n",
        "\n",
        "# 6. What are continuous and categorical variables?\n",
        "# Continuous variables are numerical variables that can take an infinite range of values, such as height, weight, or temperature.\n",
        "# Categorical variables, on the other hand, represent categories or labels, such as gender, color, or product type.\n",
        "# Machine learning models handle these variable types differently, often requiring encoding for categorical data.\n",
        "\n",
        "# 7. How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "# Since most machine learning models require numerical inputs, categorical variables need to be transformed.\n",
        "# Common techniques include label encoding (assigning numeric values to categories), one-hot encoding (creating binary columns for each category), and target encoding.\n",
        "# The choice of encoding technique depends on the model type and data characteristics.\n",
        "\n",
        "# 8. What do you mean by training and testing a dataset?\n",
        "# The dataset is split into two parts: the training set, used to train the model, and the test set, used to evaluate its performance.\n",
        "# The training set helps the model learn patterns, while the test set checks if the model generalizes well to unseen data.\n",
        "# Proper data splitting ensures that the model does not overfit to the training data.\n",
        "\n",
        "# 9. What is sklearn.preprocessing?\n",
        "# The sklearn.preprocessing module in Scikit-learn provides functions for feature scaling, encoding categorical variables, and transforming data.\n",
        "# It includes tools like StandardScaler for normalization, OneHotEncoder for categorical encoding, and PolynomialFeatures for feature expansion.\n",
        "# These preprocessing steps help improve model performance and compatibility with various algorithms.\n",
        "\n",
        "# 10. What is a Test set?\n",
        "# A test set is a portion of the dataset reserved for evaluating the trained model’s performance.\n",
        "# It helps assess how well the model generalizes to new, unseen data.\n",
        "# A properly chosen test set ensures unbiased performance measurement.\n",
        "\n",
        "# 11. How do we split data for model fitting (training and testing) in Python?\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# This splits the dataset into 80% training data and 20% testing data, ensuring reproducibility with random_state.\n",
        "\n",
        "# 12. How do you approach a Machine Learning problem?\n",
        "# The typical approach involves defining the problem, collecting and cleaning data, performing exploratory data analysis (EDA), choosing and training a model, and evaluating its performance.\n",
        "# Further tuning and optimization may be required to enhance model accuracy.\n",
        "# Finally, the model is deployed, monitored, and maintained for real-world usage.\n",
        "\n",
        "# 13. Why do we have to perform EDA before fitting a model to the data?\n",
        "# Exploratory Data Analysis (EDA) helps understand the dataset’s structure, distribution, and relationships.\n",
        "# It allows us to detect missing values, outliers, and patterns that can influence model performance.\n",
        "# Proper EDA ensures better preprocessing, feature selection, and model selection.\n",
        "\n",
        "# 14. What is correlation?\n",
        "# Correlation measures the statistical relationship between two variables.\n",
        "# It helps identify dependencies that can be useful in feature selection for machine learning models.\n",
        "# Different correlation types include Pearson, Spearman, and Kendall correlation.\n",
        "\n",
        "# 15. What does negative correlation mean?\n",
        "# A negative correlation means that as one variable increases, the other decreases.\n",
        "# It is represented by a correlation coefficient between -1 and 0.\n",
        "# For example, an increase in study time may lead to a decrease in failure rates.\n",
        "\n",
        "# 16. How can you find correlation between variables in Python?\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "df.corr()\n",
        "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
        "# The heatmap visually represents correlations among variables.\n",
        "\n",
        "# 17. What is causation? Explain difference between correlation and causation with an example.\n",
        "# Causation implies that one event directly affects another, while correlation only suggests a relationship without proving causality.\n",
        "# Example: More ice cream sales and more drowning incidents are correlated, but the cause is the hot weather.\n",
        "# In contrast, smoking causes lung cancer, showing causation.\n",
        "\n",
        "# 18. What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "# Optimizers adjust model parameters to minimize loss.\n",
        "# Common types: Gradient Descent (simple but slow), Adam (adaptive learning rates), RMSprop (suited for non-stationary objectives).\n",
        "# Example: Adam optimizer is often used in deep learning models due to its efficiency.\n",
        "\n",
        "# 19. What is sklearn.linear_model?\n",
        "# It is a Scikit-learn module that provides linear regression models for predictive analysis.\n",
        "# It includes algorithms like Linear Regression, Logistic Regression, and Ridge Regression.\n",
        "\n",
        "# 20. What does model.fit() do? What arguments must be given?\n",
        "# It trains the model using input features (X) and target labels (y).\n",
        "# Example: model.fit(X_train, y_train)\n",
        "\n",
        "# 21. What does model.predict() do? What arguments must be given?\n",
        "# It generates predictions based on input features (X).\n",
        "# Example: predictions = model.predict(X_test)\n",
        "\n",
        "# 22. What is feature scaling? How does it help in Machine Learning?\n",
        "# Feature scaling normalizes numerical values to a uniform range, improving model efficiency.\n",
        "# Methods: Standardization (mean=0, variance=1), Normalization (range 0 to 1).\n",
        "\n",
        "# 23. How do we perform scaling in Python?\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# 24. Explain data encoding?\n",
        "# Data encoding converts categorical variables into numeric formats for ML models.\n",
        "# Common techniques include One-Hot Encoding, Label Encoding, Ordinal Encoding, and Target Encoding.\n",
        "# Encoding helps models interpret categorical data efficiently and improve performance.\n",
        "\n",
        "# 25. How do we split data for model fitting (training and testing) in Python?\n",
        "# We use train_test_split from sklearn.model_selection.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# This ensures a balanced and reproducible data split for model training and evaluation.\n"
      ],
      "metadata": {
        "id": "QTrosMcya7TR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}